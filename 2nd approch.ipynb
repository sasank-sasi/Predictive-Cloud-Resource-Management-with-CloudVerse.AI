{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phase -1 import data and define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset_path = \"vmCloud_data.csv\"\n",
    "Cloud_data = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  vm_id            timestamp  cpu_usage  \\\n",
      "0  c5215826-6237-4a33-9312-72c1df909881  2023-01-25 09:10:54  54.881350   \n",
      "1  29690bc6-1f34-403b-b509-a1ecb1834fb8  2023-01-26 04:46:34  71.518937   \n",
      "2  2e55abc3-5bad-46cb-b445-a577f5e9bf2a  2023-01-13 23:39:47        NaN   \n",
      "3  e672e32f-c134-4fbc-992b-34eb63bef6bf  2023-02-09 11:45:49  54.488318   \n",
      "4  f38b8b50-6926-4533-be4f-89ad11624071  2023-06-14 08:27:26  42.365480   \n",
      "\n",
      "   memory_usage  network_traffic  power_consumption  \\\n",
      "0     78.950861       164.775973         287.808986   \n",
      "1     29.901883              NaN         362.273569   \n",
      "2     92.709195       203.674847         231.467903   \n",
      "3     88.100960              NaN         195.639954   \n",
      "4           NaN              NaN         359.451537   \n",
      "\n",
      "   num_executed_instructions  execution_time  energy_efficiency task_type  \\\n",
      "0                     7527.0       69.345575           0.553589   network   \n",
      "1                     5348.0       41.396040           0.349856        io   \n",
      "2                     5483.0       24.602549           0.796277        io   \n",
      "3                     5876.0       16.456670           0.529511   compute   \n",
      "4                     3361.0       55.307992           0.351907       NaN   \n",
      "\n",
      "  task_priority task_status  \n",
      "0        medium     waiting  \n",
      "1          high   completed  \n",
      "2        medium   completed  \n",
      "3          high   completed  \n",
      "4        medium     waiting  \n"
     ]
    }
   ],
   "source": [
    "print(Cloud_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['vm_id', 'timestamp', 'cpu_usage', 'memory_usage', 'network_traffic',\n",
      "       'power_consumption', 'num_executed_instructions', 'execution_time',\n",
      "       'energy_efficiency', 'task_type', 'task_priority', 'task_status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(Cloud_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phase - 2 * preprocessing the data and normalizing the values and cleaning the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['vm_id', 'timestamp', 'cpu_usage', 'memory_usage', 'network_traffic',\n",
      "       'power_consumption', 'num_executed_instructions', 'execution_time',\n",
      "       'energy_efficiency', 'task_type', 'task_priority', 'task_status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"vmCloud_data.csv\")\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Handle missing values\n",
    "numerical_cols = ['cpu_usage', 'memory_usage', 'network_traffic', 'power_consumption', \n",
    "                  'num_executed_instructions', 'execution_time', 'energy_efficiency']\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[numerical_cols] = imputer.fit_transform(df[numerical_cols])\n",
    "\n",
    "# For categorical columns, you might want to fill missing values with a placeholder or the most frequent value\n",
    "categorical_cols = ['task_type', 'task_priority', 'task_status']\n",
    "df[categorical_cols] = df[categorical_cols].fillna('missing')\n",
    "\n",
    "# Normalize or Standardize the numerical data\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is already defined and includes a 'timestamp' and 'cpu_usage' column\n",
    "\n",
    "# Convert 'timestamp' to datetime and set as index\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "df = df.dropna(subset=['timestamp'])  # Drop rows where 'timestamp' is NaT\n",
    "df.set_index('timestamp', inplace=True)\n",
    "df.sort_index(inplace=True)  # Sort the DataFrame by the index\n",
    "\n",
    "# Apply rolling averages\n",
    "df['cpu_usage_rolling_mean_3h'] = df['cpu_usage'].rolling(window='3h').mean()\n",
    "df['cpu_usage_rolling_mean_6h'] = df['cpu_usage'].rolling(window='6h').mean()\n",
    "\n",
    "# Ensure the index is unique before applying shift operations\n",
    "if df.index.duplicated().any():\n",
    "    df = df[~df.index.duplicated(keep='first')]  # Drop duplicates, keeping the first occurrence\n",
    "\n",
    "# Apply shift operations without 'freq' to avoid reindexing issues\n",
    "df['cpu_usage_lag_1h'] = df['cpu_usage'].shift(periods=1)  # Shift by 1 period instead of using 'freq'\n",
    "df['cpu_usage_lag_1d'] = df['cpu_usage'].shift(periods=24)  # Assuming hourly data, shift by 24 periods for 1 day\n",
    "\n",
    "# Extract time components\n",
    "df['hour_of_day'] = df.index.hour\n",
    "df['day_of_week'] = df.index.dayofweek\n",
    "\n",
    "# Drop rows with NaN values created by rolling and lag features\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Prepare a DataFrame for Prophet\n",
    "prophet_df = df.reset_index()[['timestamp', 'cpu_usage']].rename(columns={'timestamp': 'ds', 'cpu_usage': 'y'})\n",
    "\n",
    "# The 'df' DataFrame now includes both original and engineered features and can be used directly for models like Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "00:11:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:14:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "# Initialize the Prophet model\n",
    "model = Prophet()\n",
    "\n",
    "# Fit the model with your DataFrame\n",
    "model.fit(prophet_df)\n",
    "\n",
    "# Create a future DataFrame for the next 365 days\n",
    "future = model.make_future_dataframe(periods=365)\n",
    "\n",
    "# Predict future values\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Plot the forecast including the trend and seasonality components\n",
    "fig1 = model.plot(forecast)\n",
    "fig2 = model.plot_components(forecast)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
